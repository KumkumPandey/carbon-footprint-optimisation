{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee38abdf-3685-4063-b34a-2fecc45eab60",
   "metadata": {},
   "source": [
    "# Data Collection & Preparation (The Foundation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d197577-a31e-4938-8171-d2a9f15a9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64606e8-c7b1-4d67-bce9-d8af239d9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76f0fb4-70ee-4a44-8383-eebaeaa25f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.9 MB/s  0:00:00\n",
      "Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   ---------------------------------------- 2/2 [sqlalchemy]\n",
      "\n",
      "Successfully installed greenlet-3.2.4 sqlalchemy-2.0.43\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Downloading geographiclib-2.1-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   ---------------------------------------- 2/2 [geopy]\n",
      "\n",
      "Successfully installed geographiclib-2.1 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a25b68-55e7-40bb-b612-a3ef9d1ce047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "050b20df-0588-49d0-9acd-772a56390770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into the 'routes' table.\n",
      "\n",
      "Verifying data with a SQL query:\n",
      "  truck_id start_location end_location  load_weight_kg\n",
      "0     T001      New Delhi       Mumbai            5000\n",
      "1     T002      Bangalore      Chennai            3500\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a database file\n",
    "engine = create_engine('sqlite:///logistics.db')\n",
    "\n",
    "# Step 2: Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('logistics_data.csv')\n",
    "\n",
    "# Step 3: Write the DataFrame to a SQL table named 'routes'\n",
    "# if_exists='replace' will create a new table every time this script is run\n",
    "df.to_sql('routes', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data successfully loaded into the 'routes' table.\")\n",
    "\n",
    "# You can even run a simple SQL query to verify\n",
    "with engine.connect() as conn:\n",
    "    query = \"SELECT * FROM routes LIMIT 2\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    print(\"\\nVerifying data with a SQL query:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8151ee6d-38ee-4ac8-9a4e-ec1539f9d90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Saved to 'processed_logistics_data.csv'\n",
      "\n",
      "Final Processed Data (First 5 rows):\n",
      "  truck_id start_location end_location  load_weight_kg weather_condition  \\\n",
      "0     T001      New Delhi       Mumbai            5000             Foggy   \n",
      "1     T002      Bangalore      Chennai            3500             Clear   \n",
      "2     T003      Hyderabad         Pune            6200             Foggy   \n",
      "3     T004         Mumbai      Kolkata            4800             Foggy   \n",
      "4     T005      New Delhi    Bangalore            5500             Clear   \n",
      "\n",
      "  traffic_level time_of_day  distance_km  base_carbon_kg  total_carbon_kg  \n",
      "0           Low   Afternoon  1149.608388      279.921678       335.906013  \n",
      "1        Medium       Night   290.543167       93.108633       134.076432  \n",
      "2        Medium   Afternoon   506.291027      163.258205       235.091816  \n",
      "3        Medium   Afternoon  1656.861150      379.372230       546.296011  \n",
      "4        Medium       Night  1742.650905      403.530181       581.083461  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Connect to the database and load the data\n",
    "engine = create_engine('sqlite:///logistics.db')\n",
    "df = pd.read_sql_table('routes', engine)\n",
    "\n",
    "# Step 2: Simulate real-time data (weather and traffic)\n",
    "np.random.seed(42) # For consistent results\n",
    "df['weather_condition'] = np.random.choice(['Clear', 'Rainy', 'Foggy'], len(df))\n",
    "df['traffic_level'] = np.random.choice(['Low', 'Medium', 'High'], len(df))\n",
    "df['time_of_day'] = np.random.choice(['Morning', 'Afternoon', 'Night'], len(df))\n",
    "\n",
    "# Step 3: Calculate distance using geopy\n",
    "# We need to get coordinates for each city. Let's use some example coordinates.\n",
    "# In a real project, you would use a geocoding service.\n",
    "city_coords = {\n",
    "    \"New Delhi\": (28.7041, 77.1025),\n",
    "    \"Mumbai\": (19.0760, 72.8777),\n",
    "    \"Bangalore\": (12.9716, 77.5946),\n",
    "    \"Chennai\": (13.0827, 80.2707),\n",
    "    \"Hyderabad\": (17.3850, 78.4867),\n",
    "    \"Pune\": (18.5204, 73.8567),\n",
    "    \"Kolkata\": (22.5726, 88.3639)\n",
    "}\n",
    "\n",
    "def calculate_distance(row):\n",
    "    start_point = city_coords[row['start_location']]\n",
    "    end_point = city_coords[row['end_location']]\n",
    "    return geodesic(start_point, end_point).km\n",
    "\n",
    "df['distance_km'] = df.apply(calculate_distance, axis=1)\n",
    "\n",
    "# Step 4: A simple proxy for carbon footprint based on features\n",
    "# This is our target variable for the machine learning model.\n",
    "df['base_carbon_kg'] = df['distance_km'] * 0.2 + df['load_weight_kg'] * 0.01  # Example formula\n",
    "weather_impact = {'Clear': 1.0, 'Rainy': 1.1, 'Foggy': 1.2}\n",
    "traffic_impact = {'Low': 1.0, 'Medium': 1.2, 'High': 1.5}\n",
    "time_impact = {'Morning': 1.1, 'Afternoon': 1.0, 'Night': 1.2}\n",
    "\n",
    "df['total_carbon_kg'] = (\n",
    "    df['base_carbon_kg'] * df['weather_condition'].map(weather_impact) *\n",
    "    df['traffic_level'].map(traffic_impact) *\n",
    "    df['time_of_day'].map(time_impact)\n",
    ")\n",
    "\n",
    "# Step 5: Save the preprocessed data for the next step (Model Building)\n",
    "df.to_csv('processed_logistics_data.csv', index=False)\n",
    "print(\"Data preprocessing complete. Saved to 'processed_logistics_data.csv'\")\n",
    "print(\"\\nFinal Processed Data (First 5 rows):\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728d45c-2dcc-4e5e-8f9e-4199e7ed5bb5",
   "metadata": {},
   "source": [
    "# Predictive Model Building (The Brains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d4cd4a-9c44-4ef2-9d97-1ea3cf7502ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f10244d5-da2a-434e-a0c6-605bd3f0a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded processed data.\n",
      "\n",
      "Features after One-Hot Encoding:\n",
      "   distance_km  load_weight_kg  weather_condition_Clear  \\\n",
      "0  1149.608388            5000                      0.0   \n",
      "1   290.543167            3500                      1.0   \n",
      "2   506.291027            6200                      0.0   \n",
      "3  1656.861150            4800                      0.0   \n",
      "4  1742.650905            5500                      1.0   \n",
      "\n",
      "   weather_condition_Foggy  weather_condition_Rainy  traffic_level_High  \\\n",
      "0                      1.0                      0.0                 0.0   \n",
      "1                      0.0                      0.0                 0.0   \n",
      "2                      1.0                      0.0                 0.0   \n",
      "3                      1.0                      0.0                 0.0   \n",
      "4                      0.0                      0.0                 0.0   \n",
      "\n",
      "   traffic_level_Low  traffic_level_Medium  time_of_day_Afternoon  \\\n",
      "0                1.0                   0.0                    1.0   \n",
      "1                0.0                   1.0                    0.0   \n",
      "2                0.0                   1.0                    1.0   \n",
      "3                0.0                   1.0                    1.0   \n",
      "4                0.0                   1.0                    0.0   \n",
      "\n",
      "   time_of_day_Morning  time_of_day_Night  \n",
      "0                  0.0                0.0  \n",
      "1                  0.0                1.0  \n",
      "2                  0.0                0.0  \n",
      "3                  0.0                0.0  \n",
      "4                  0.0                1.0  \n",
      "\n",
      "Training set size: 12 rows\n",
      "Testing set size: 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Data Loading & Splitting\n",
    "\n",
    "# Step 1: Load the preprocessed data\n",
    "df = pd.read_csv('processed_logistics_data.csv')\n",
    "print(\"Loaded processed data.\")\n",
    "\n",
    "# Step 2: Define features (X) and target (y)\n",
    "# We will drop the original categorical columns after encoding them.\n",
    "features = ['distance_km', 'load_weight_kg', 'weather_condition', 'traffic_level', 'time_of_day']\n",
    "X = df[features]\n",
    "y = df['total_carbon_kg']\n",
    "\n",
    "# Step 3: Handle categorical data (One-Hot Encoding)\n",
    "# Machine learning models only understand numbers, so we convert text into numbers.\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X[['weather_condition', 'traffic_level', 'time_of_day']])\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Drop original categorical columns and add the encoded ones\n",
    "X = X.drop(columns=['weather_condition', 'traffic_level', 'time_of_day'])\n",
    "X = pd.concat([X.reset_index(drop=True), X_encoded_df], axis=1)\n",
    "\n",
    "print(\"\\nFeatures after One-Hot Encoding:\")\n",
    "print(X.head())\n",
    "\n",
    "# Step 4: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} rows\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "974ed73b-0e6b-4b69-8071-009cbab3dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training complete.\n",
      "\n",
      "Model Performance Metrics:\n",
      "Mean Absolute Error (MAE): 33.17 kg\n",
      "R-squared Score (R2): -0.18\n"
     ]
    }
   ],
   "source": [
    "#Model Training & Evaluation\n",
    "\n",
    "# Step 5: Initialize and train the Machine Learning model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModel training complete.\")\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model's performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} kg\")\n",
    "print(f\"R-squared Score (R2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96f2d5-c5c2-4bda-b78c-91e2f833d163",
   "metadata": {},
   "source": [
    "# Optimization & Recommendation System (The Unique Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "960a8506-4edb-4fbb-93fa-46338600ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "#Create a Prediction Function\n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e2f87c4-fd75-4144-8c99-c868cd60b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted carbon footprint for a sample trip: 400.95 kg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# 1. Load the trained model and encoder\n",
    "# Note: Aapko pehle model aur encoder ko save karna hoga.\n",
    "# Upar ke code mein, model.fit() ke baad ye code add karein:\n",
    "# joblib.dump(model, 'carbon_model.pkl')\n",
    "# joblib.dump(encoder, 'onehot_encoder.pkl')\n",
    "\n",
    "# Assuming you have saved them:\n",
    "model = joblib.load('carbon_model.pkl')\n",
    "encoder = joblib.load('onehot_encoder.pkl')\n",
    "\n",
    "# 2. Define city coordinates and impact factors (same as before)\n",
    "city_coords = {\n",
    "    \"New Delhi\": (28.7041, 77.1025), \"Mumbai\": (19.0760, 72.8777),\n",
    "    \"Bangalore\": (12.9716, 77.5946), \"Chennai\": (13.0827, 80.2707),\n",
    "    \"Hyderabad\": (17.3850, 78.4867), \"Pune\": (18.5204, 73.8567),\n",
    "    \"Kolkata\": (22.5726, 88.3639)\n",
    "}\n",
    "\n",
    "weather_impact = {'Clear': 1.0, 'Rainy': 1.1, 'Foggy': 1.2}\n",
    "traffic_impact = {'Low': 1.0, 'Medium': 1.2, 'High': 1.5}\n",
    "time_impact = {'Morning': 1.1, 'Afternoon': 1.0, 'Night': 1.2}\n",
    "\n",
    "def predict_carbon_footprint(start_loc, end_loc, load_kg, weather, traffic, time_of_day):\n",
    "    # Calculate distance\n",
    "    dist_km = geodesic(city_coords[start_loc], city_coords[end_loc]).km\n",
    "\n",
    "    # Create a DataFrame for prediction\n",
    "    # Column names must match the training data\n",
    "    input_data = pd.DataFrame([{\n",
    "        'distance_km': dist_km,\n",
    "        'load_weight_kg': load_kg,\n",
    "        'weather_condition': weather,\n",
    "        'traffic_level': traffic,\n",
    "        'time_of_day': time_of_day\n",
    "    }])\n",
    "\n",
    "    # Apply the same one-hot encoding as during training\n",
    "    categorical_features = ['weather_condition', 'traffic_level', 'time_of_day']\n",
    "    encoded_features = encoder.transform(input_data[categorical_features])\n",
    "    encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
    "\n",
    "    # Combine numerical and encoded features\n",
    "    final_input = pd.concat([\n",
    "        input_data[['distance_km', 'load_weight_kg']].reset_index(drop=True),\n",
    "        encoded_df\n",
    "    ], axis=1)\n",
    "\n",
    "    # Predict using the trained model\n",
    "    prediction = model.predict(final_input)\n",
    "    return prediction[0]\n",
    "\n",
    "# Let's test the function\n",
    "sample_prediction = predict_carbon_footprint(\"New Delhi\", \"Mumbai\", 5000, \"Clear\", \"High\", \"Morning\")\n",
    "print(f\"\\nPredicted carbon footprint for a sample trip: {sample_prediction:.2f} kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "420d159d-b401-4d42-8800-dd1da593ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimized Route Recommendation ---\n",
      "Start Location: New Delhi\n",
      "End Location: Mumbai\n",
      "Recommended Time: Morning with Low traffic and Rainy weather.\n",
      "Optimized Carbon Footprint: 345.51 kg\n"
     ]
    }
   ],
   "source": [
    "# Build the Optimization Logic\n",
    "\n",
    "# Step 3: Optimization function to find the best route/scenario\n",
    "def find_best_route_scenario(start_loc, end_loc, load_kg):\n",
    "    # Define all possible scenarios\n",
    "    possible_scenarios = []\n",
    "    weathers = ['Clear', 'Rainy'] # Simplified for example\n",
    "    traffics = ['Low', 'Medium', 'High']\n",
    "    times = ['Morning', 'Afternoon', 'Night']\n",
    "\n",
    "    for weather in weathers:\n",
    "        for traffic in traffics:\n",
    "            for time in times:\n",
    "                carbon_kg = predict_carbon_footprint(\n",
    "                    start_loc, end_loc, load_kg, weather, traffic, time\n",
    "                )\n",
    "                possible_scenarios.append({\n",
    "                    'start_location': start_loc,\n",
    "                    'end_location': end_loc,\n",
    "                    'load_kg': load_kg,\n",
    "                    'weather': weather,\n",
    "                    'traffic': traffic,\n",
    "                    'time_of_day': time,\n",
    "                    'carbon_kg': carbon_kg\n",
    "                })\n",
    "\n",
    "    # Find the scenario with the minimum carbon footprint\n",
    "    best_scenario = min(possible_scenarios, key=lambda x: x['carbon_kg'])\n",
    "    return best_scenario\n",
    "\n",
    "# Let's test the optimization logic\n",
    "best_option = find_best_route_scenario(\"New Delhi\", \"Mumbai\", 5000)\n",
    "print(\"\\n--- Optimized Route Recommendation ---\")\n",
    "print(f\"Start Location: {best_option['start_location']}\")\n",
    "print(f\"End Location: {best_option['end_location']}\")\n",
    "print(f\"Recommended Time: {best_option['time_of_day']} with {best_option['traffic']} traffic and {best_option['weather']} weather.\")\n",
    "print(f\"Optimized Carbon Footprint: {best_option['carbon_kg']:.2f} kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d12b8487-2128-4c94-b156-25ec6478327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5e01c-3684-48f1-894f-2074f658666a",
   "metadata": {},
   "source": [
    "# PyTorch for Time-Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2fdc2c8-c062-4ef5-b769-0107f02eb376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch models and scalers saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Dummy Time-Series Data (Replace with real data)\n",
    "# Real data will have 'time', 'traffic_level', 'weather_condition'\n",
    "data = {\n",
    "    'time': pd.to_datetime(pd.date_range(start='2025-01-01', periods=100, freq='h')),\n",
    "    'traffic_level': np.random.randint(1, 4, 100),\n",
    "    'weather_condition': np.random.randint(1, 4, 100)\n",
    "}\n",
    "df = pd.DataFrame(data).set_index('time')\n",
    "\n",
    "# 2. Preprocess Data\n",
    "scaler_traffic = MinMaxScaler()\n",
    "scaler_weather = MinMaxScaler()\n",
    "df['traffic_scaled'] = scaler_traffic.fit_transform(df[['traffic_level']])\n",
    "df['weather_scaled'] = scaler_weather.fit_transform(df[['weather_condition']])\n",
    "\n",
    "# 3. Create Sequences for LSTM\n",
    "def create_sequences(input_data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(input_data) - sequence_length):\n",
    "        seq = input_data[i:i + sequence_length]\n",
    "        label = input_data[i + sequence_length]\n",
    "        sequences.append((seq, label))\n",
    "    return sequences\n",
    "\n",
    "sequence_length = 12 # Predict based on last 12 hours\n",
    "traffic_sequences = create_sequences(df['traffic_scaled'].values, sequence_length)\n",
    "weather_sequences = create_sequences(df['weather_scaled'].values, sequence_length)\n",
    "\n",
    "# 4. Define LSTM Model\n",
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=50, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "\n",
    "# 5. Train the models (Traffic and Weather)\n",
    "def train_model(sequences, scaler):\n",
    "    model = LSTMForecaster()\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    epochs = 50\n",
    "    for i in range(epochs):\n",
    "        for seq, labels in sequences:\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                                 torch.zeros(1, 1, model.hidden_layer_size))\n",
    "            y_pred = model(torch.Tensor(seq).view(-1, 1))\n",
    "            single_loss = loss_function(y_pred, torch.Tensor([labels]))\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "traffic_model = train_model(traffic_sequences, scaler_traffic)\n",
    "weather_model = train_model(weather_sequences, scaler_weather)\n",
    "\n",
    "# 6. Save the models and scalers\n",
    "torch.save(traffic_model.state_dict(), 'traffic_lstm.pth')\n",
    "torch.save(weather_model.state_dict(), 'weather_lstm.pth')\n",
    "joblib.dump(scaler_traffic, 'scaler_traffic.pkl')\n",
    "joblib.dump(scaler_weather, 'scaler_weather.pkl')\n",
    "\n",
    "print(\"PyTorch models and scalers saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877b796-6864-4c1b-9b48-2e2315a5a0d6",
   "metadata": {},
   "source": [
    "# TensorFlow for Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05541bda-5c8f-443b-b07b-d222346f039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.1.1)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kumku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/331.9 MB 3.3 MB/s eta 0:01:40\n",
      "   ---------------------------------------- 1.3/331.9 MB 4.2 MB/s eta 0:01:19\n",
      "   ---------------------------------------- 2.4/331.9 MB 4.3 MB/s eta 0:01:17\n",
      "   ---------------------------------------- 3.9/331.9 MB 5.2 MB/s eta 0:01:03\n",
      "    --------------------------------------- 5.8/331.9 MB 6.1 MB/s eta 0:00:54\n",
      "    --------------------------------------- 7.6/331.9 MB 6.6 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 10.5/331.9 MB 7.7 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 13.1/331.9 MB 8.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 15.2/331.9 MB 8.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 17.3/331.9 MB 8.7 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 19.7/331.9 MB 8.9 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 22.0/331.9 MB 9.2 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 24.4/331.9 MB 9.3 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 26.7/331.9 MB 9.4 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 29.1/331.9 MB 9.6 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 32.0/331.9 MB 9.9 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 34.6/331.9 MB 10.0 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 36.4/331.9 MB 9.9 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 38.8/331.9 MB 10.0 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 41.2/331.9 MB 10.0 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 43.5/331.9 MB 10.1 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 45.9/331.9 MB 10.1 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 48.0/331.9 MB 10.1 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 50.1/331.9 MB 10.1 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 52.4/331.9 MB 10.1 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 54.5/331.9 MB 10.1 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 55.8/331.9 MB 10.0 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 57.9/331.9 MB 10.0 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 59.8/331.9 MB 10.0 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 61.9/331.9 MB 10.0 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 63.7/331.9 MB 10.0 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 65.5/331.9 MB 9.9 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 67.1/331.9 MB 9.8 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 68.7/331.9 MB 9.7 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 70.3/331.9 MB 9.7 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 71.6/331.9 MB 9.6 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 73.4/331.9 MB 9.6 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 75.5/331.9 MB 9.6 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 76.8/331.9 MB 9.5 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 78.9/331.9 MB 9.5 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 80.7/331.9 MB 9.5 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 82.6/331.9 MB 9.5 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 84.1/331.9 MB 9.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 85.5/331.9 MB 9.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 86.8/331.9 MB 9.3 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 88.1/331.9 MB 9.2 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 89.7/331.9 MB 9.2 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 91.0/331.9 MB 9.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 92.5/331.9 MB 9.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 94.1/331.9 MB 9.0 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 95.7/331.9 MB 9.0 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 97.3/331.9 MB 9.0 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 98.8/331.9 MB 8.9 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 100.7/331.9 MB 8.9 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 101.7/331.9 MB 8.9 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 103.0/331.9 MB 8.8 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 104.3/331.9 MB 8.8 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 105.6/331.9 MB 8.7 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 107.0/331.9 MB 8.7 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 108.0/331.9 MB 8.7 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 109.6/331.9 MB 8.6 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 110.9/331.9 MB 8.6 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 112.2/331.9 MB 8.5 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 113.5/331.9 MB 8.5 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 115.1/331.9 MB 8.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 116.7/331.9 MB 8.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 118.0/331.9 MB 8.4 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 119.3/331.9 MB 8.4 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 120.8/331.9 MB 8.4 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 122.2/331.9 MB 8.4 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 123.7/331.9 MB 8.4 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 125.3/331.9 MB 8.3 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 127.1/331.9 MB 8.3 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 128.5/331.9 MB 8.3 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 130.3/331.9 MB 8.3 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 131.9/331.9 MB 8.3 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 133.2/331.9 MB 8.3 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 134.7/331.9 MB 8.3 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 136.3/331.9 MB 8.3 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 137.9/331.9 MB 8.3 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 139.7/331.9 MB 8.3 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 141.0/331.9 MB 8.2 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 142.9/331.9 MB 8.2 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 145.0/331.9 MB 8.3 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 146.3/331.9 MB 8.2 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 147.6/331.9 MB 8.2 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 148.9/331.9 MB 8.2 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 150.5/331.9 MB 8.2 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 151.8/331.9 MB 8.2 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 153.4/331.9 MB 8.2 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 154.7/331.9 MB 8.1 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 156.2/331.9 MB 8.1 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 157.5/331.9 MB 8.1 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 158.9/331.9 MB 8.1 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 160.2/331.9 MB 8.1 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 161.5/331.9 MB 8.0 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 162.8/331.9 MB 8.0 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 163.8/331.9 MB 8.0 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 165.2/331.9 MB 8.0 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 166.5/331.9 MB 8.0 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 167.8/331.9 MB 7.9 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 169.1/331.9 MB 7.9 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 170.4/331.9 MB 7.9 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 172.0/331.9 MB 7.9 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 173.3/331.9 MB 7.9 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 174.9/331.9 MB 7.9 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 176.4/331.9 MB 7.9 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 178.0/331.9 MB 7.9 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 179.6/331.9 MB 7.9 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 181.4/331.9 MB 7.9 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 183.0/331.9 MB 7.9 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 184.5/331.9 MB 7.9 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 186.4/331.9 MB 7.9 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 188.0/331.9 MB 7.9 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 190.1/331.9 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 191.6/331.9 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 193.5/331.9 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 195.0/331.9 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 196.9/331.9 MB 7.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 198.7/331.9 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 200.5/331.9 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 202.4/331.9 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 204.5/331.9 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 206.3/331.9 MB 7.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 208.1/331.9 MB 7.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 209.7/331.9 MB 7.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 211.0/331.9 MB 7.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 212.6/331.9 MB 7.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 213.9/331.9 MB 7.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 215.7/331.9 MB 7.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 217.3/331.9 MB 7.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 219.2/331.9 MB 7.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 221.0/331.9 MB 7.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 222.6/331.9 MB 7.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 224.4/331.9 MB 7.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 226.5/331.9 MB 7.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 228.3/331.9 MB 7.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 230.2/331.9 MB 7.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 231.7/331.9 MB 8.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 233.8/331.9 MB 8.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 235.4/331.9 MB 8.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 237.5/331.9 MB 8.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 239.3/331.9 MB 8.0 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 241.4/331.9 MB 8.0 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 243.3/331.9 MB 8.0 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 245.4/331.9 MB 8.1 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 247.2/331.9 MB 8.1 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 248.3/331.9 MB 8.1 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 250.1/331.9 MB 8.0 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 251.4/331.9 MB 8.0 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 253.0/331.9 MB 8.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 254.5/331.9 MB 8.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 256.1/331.9 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 257.7/331.9 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 259.5/331.9 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 261.1/331.9 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 262.7/331.9 MB 7.8 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 264.5/331.9 MB 7.8 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 266.6/331.9 MB 7.8 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 268.4/331.9 MB 7.8 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 270.3/331.9 MB 7.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 272.1/331.9 MB 7.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 273.9/331.9 MB 7.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 275.8/331.9 MB 7.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 277.6/331.9 MB 7.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 279.4/331.9 MB 7.7 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 281.3/331.9 MB 7.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 283.4/331.9 MB 7.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 285.2/331.9 MB 7.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 287.3/331.9 MB 7.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 289.1/331.9 MB 7.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 291.0/331.9 MB 7.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 293.1/331.9 MB 7.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 294.4/331.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 296.2/331.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 298.1/331.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 300.2/331.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 301.7/331.9 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 303.3/331.9 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 304.3/331.9 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 305.7/331.9 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 306.7/331.9 MB 7.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 308.0/331.9 MB 7.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 309.1/331.9 MB 7.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 309.9/331.9 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 310.9/331.9 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 312.0/331.9 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 312.7/331.9 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 313.8/331.9 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 314.8/331.9 MB 7.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 315.9/331.9 MB 7.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 316.9/331.9 MB 7.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 318.0/331.9 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 319.0/331.9 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 320.3/331.9 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 321.4/331.9 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 322.4/331.9 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  323.7/331.9 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.1/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  326.4/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  327.7/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.0/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.0/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.4/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.9/331.9 MB 6.0 MB/s  0:00:48\n",
      "Downloading grpcio-1.74.0-cp312-cp312-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.3/4.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.6/4.5 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.2/4.5 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.5/4.5 MB 5.6 MB/s  0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 6.5 MB/s  0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.6/2.9 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 6.2 MB/s  0:00:00\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 1.3/1.4 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 5.6 MB/s  0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/26.4 MB 4.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.6/26.4 MB 3.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.6/26.4 MB 4.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 4.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 4.5/26.4 MB 4.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.5/26.4 MB 4.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.6/26.4 MB 4.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.6/26.4 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.7/26.4 MB 4.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.7/26.4 MB 4.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 12.1/26.4 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.4/26.4 MB 5.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 14.4/26.4 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.8/26.4 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.4 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.4/26.4 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.4/26.4 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.5/26.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.9/26.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 4.8 MB/s  0:00:05\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.0-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, astunparse, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   --- ------------------------------------  2/21 [flatbuffers]\n",
      "   ----- ----------------------------------  3/21 [wrapt]\n",
      "   ------- --------------------------------  4/21 [wheel]\n",
      "   --------- ------------------------------  5/21 [termcolor]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   --------------- ------------------------  8/21 [optree]\n",
      "   --------------- ------------------------  8/21 [optree]\n",
      "   ----------------- ----------------------  9/21 [opt_einsum]\n",
      "   -------------------- ------------------- 11/21 [markdown]\n",
      "   -------------------- ------------------- 11/21 [markdown]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   -------------------------- ------------- 14/21 [google_pasta]\n",
      "   -------------------------- ------------- 14/21 [google_pasta]\n",
      "   ------------------------------ --------- 16/21 [absl-py]\n",
      "   ------------------------------ --------- 16/21 [absl-py]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   ---------------------------------------- 21/21 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 keras-3.11.3 libclang-18.1.1 markdown-3.8.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.32.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 wheel-0.45.1 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4d93bca-59d2-48f9-a6ed-8dbe42f57228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56f41335-3eb5-47ff-84f0-5942d06732e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumku\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 227ms/step - accuracy: 0.4800 - loss: 1.7371 - val_accuracy: 0.5500 - val_loss: 0.6898\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4200 - loss: 0.7062 - val_accuracy: 0.5500 - val_loss: 0.6925\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5400 - loss: 0.6870 - val_accuracy: 0.4500 - val_loss: 0.7143\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5800 - loss: 0.6806 - val_accuracy: 0.4500 - val_loss: 0.7310\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5800 - loss: 0.6782 - val_accuracy: 0.4500 - val_loss: 0.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow model saved successfully as 'road_condition_classifier.h5'!\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Preparation (dummy data, replace with real image data)\n",
    "def create_dummy_dataset(num_images=100):\n",
    "    images = np.random.rand(num_images, 64, 64, 3) * 255\n",
    "    labels = np.random.randint(0, 2, num_images) # 0 for clear, 1 for congested\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = create_dummy_dataset()\n",
    "X_test, y_test = create_dummy_dataset(20)\n",
    "\n",
    "# 2. Define CNN Model\n",
    "model = keras.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(64, 64, 3)),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') # Sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# 3. Compile and Train\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# 4. Save the model\n",
    "model.save('road_condition_classifier.h5')\n",
    "print(\"TensorFlow model saved successfully as 'road_condition_classifier.h5'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3be153ff-f7cd-4562-8255-3475ab21d872",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'base_carbon_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load base model from old project\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m base_carbon_model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase_carbon_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m encoder \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot_encoder.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load PyTorch models\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'base_carbon_model.pkl'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "# Load base model from old project\n",
    "base_carbon_model = joblib.load('base_carbon_model.pkl')\n",
    "encoder = joblib.load('onehot_encoder.pkl')\n",
    "\n",
    "# Load PyTorch models\n",
    "from pytorch_forecaster import LSTMForecaster # Import the class\n",
    "traffic_lstm = LSTMForecaster()\n",
    "traffic_lstm.load_state_dict(torch.load('traffic_lstm.pth'))\n",
    "traffic_lstm.eval()\n",
    "\n",
    "weather_lstm = LSTMForecaster()\n",
    "weather_lstm.load_state_dict(torch.load('weather_lstm.pth'))\n",
    "weather_lstm.eval()\n",
    "\n",
    "scaler_traffic = joblib.load('scaler_traffic.pkl')\n",
    "scaler_weather = joblib.load('scaler_weather.pkl')\n",
    "\n",
    "# Load TensorFlow model\n",
    "road_condition_classifier = tf.keras.models.load_model('road_condition_classifier.h5')\n",
    "\n",
    "# City coordinates and impact factors (unchanged)\n",
    "city_coords = {\n",
    "    \"New Delhi\": (28.7041, 77.1025), \"Mumbai\": (19.0760, 72.8777),\n",
    "    \"Bangalore\": (12.9716, 77.5946), \"Chennai\": (13.0827, 80.2707),\n",
    "    \"Hyderabad\": (17.3850, 78.4867), \"Pune\": (18.5204, 73.8567),\n",
    "    \"Kolkata\": (22.5726, 88.3639)\n",
    "}\n",
    "weather_impact = {'Clear': 1.0, 'Rainy': 1.1, 'Foggy': 1.2}\n",
    "traffic_impact = {'Low': 1.0, 'Medium': 1.2, 'High': 1.5}\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Main prediction route\n",
    "@app.route('/predict_carbon', methods=['POST'])\n",
    "def predict_route():\n",
    "    data = request.get_json()\n",
    "    start_loc = data['start_location']\n",
    "    end_loc = data['end_location']\n",
    "    load_kg = data['load_weight_kg']\n",
    "\n",
    "    # New Feature 1: Get real-time predictions from PyTorch models\n",
    "    # Dummy current data (replace with real-time data from API)\n",
    "    current_traffic_level = np.random.randint(1, 4)\n",
    "    current_weather_level = np.random.randint(1, 4)\n",
    "    \n",
    "    # Scale the current data\n",
    "    traffic_scaled = scaler_traffic.transform([[current_traffic_level]])\n",
    "    weather_scaled = scaler_weather.transform([[current_weather_level]])\n",
    "\n",
    "    # PyTorch prediction for the next hour\n",
    "    predicted_traffic_scaled = traffic_lstm(torch.Tensor(traffic_scaled)).item()\n",
    "    predicted_weather_scaled = weather_lstm(torch.Tensor(weather_scaled)).item()\n",
    "\n",
    "    predicted_traffic_level = int(round(scaler_traffic.inverse_transform([[predicted_traffic_scaled]])[0][0]))\n",
    "    predicted_weather_level = int(round(scaler_weather.inverse_transform([[predicted_weather_scaled]])[0][0]))\n",
    "    \n",
    "    # New Feature 2: Get road condition from TensorFlow model\n",
    "    # Dummy image data (replace with a real image from an API)\n",
    "    dummy_image = np.random.rand(1, 64, 64, 3) * 255\n",
    "    road_condition_pred = road_condition_classifier.predict(dummy_image)\n",
    "    road_condition = 'Congested' if road_condition_pred > 0.5 else 'Clear'\n",
    "    \n",
    "    # Map numerical predictions back to labels\n",
    "    traffic_map = {1: 'Low', 2: 'Medium', 3: 'High'}\n",
    "    weather_map = {1: 'Clear', 2: 'Rainy', 3: 'Foggy'}\n",
    "    predicted_traffic_label = traffic_map.get(predicted_traffic_level, 'Medium')\n",
    "    predicted_weather_label = weather_map.get(predicted_weather_level, 'Clear')\n",
    "\n",
    "    # Calculate base carbon using the old model\n",
    "    dist_km = geodesic(city_coords[start_loc], city_coords[end_loc]).km\n",
    "    input_data = pd.DataFrame([[dist_km, load_kg]], columns=['distance_km', 'load_weight_kg'])\n",
    "    base_carbon_kg = base_carbon_model.predict(input_data)[0]\n",
    "\n",
    "    # Combine all predictions to get the final carbon footprint\n",
    "    final_carbon_kg = (\n",
    "        base_carbon_kg *\n",
    "        weather_impact.get(predicted_weather_label, 1.0) *\n",
    "        traffic_impact.get(predicted_traffic_label, 1.0) *\n",
    "        (1.5 if road_condition == 'Congested' else 1.0) # Apply impact from TensorFlow\n",
    "    )\n",
    "\n",
    "    return jsonify({\n",
    "        \"start_location\": start_loc,\n",
    "        \"end_location\": end_loc,\n",
    "        \"predicted_traffic\": predicted_traffic_label,\n",
    "        \"predicted_weather\": predicted_weather_label,\n",
    "        \"road_condition\": road_condition,\n",
    "        \"optimized_carbon_footprint_kg\": round(final_carbon_kg, 2)\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94618096-96ab-453c-93b5-c6b97d88b4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
